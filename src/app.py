# Proyecto con Boosting Algorithms
#  CRISP-DM CRISP-DM significa Cross Industry Standard Process for Data Mining,
# y es el est√°ndar m√°s usado en la industria para desarrollar proyectos de an√°lisis

###############   0. Business Understanding
# Este conjunto de datos proviene originalmente del Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales.
# El objetivo es predecir en base a medidas diagn√≥sticas si un paciente tiene o no diabetes.

###############   1. Data Understanding

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Cargar los datos
total_data = pd.read_csv("https://breathecode.herokuapp.com/asset/internal-link?id=930&path=diabetes.csv", sep=',')
total_data.to_csv("/workspaces/boosting-danny/data/raw/total_data.csv", sep=',', index=False)

# Exploraci√≥n inicial
print("Exploraci√≥n inicial")
print(total_data.head())
print("Filas y columnas:", total_data.shape)
print("Info:")
print(total_data.info())
print("Estad√≠sticas Descriptivas (originales):")
print(total_data.describe())

# 2.1 Verificar valores nulos o ceros sospechosos
print("\nValores nulos por columna:")
print(total_data.isnull().sum())

# 2.2 Contar valores cero en variables que no deber√≠an tenerlos
cols_with_zeros = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
for col in cols_with_zeros:
    zeros = (total_data[col] == 0).sum()
    print(f"{col}: {zeros} valores cero")

# 2.3 Visualizaci√≥n r√°pida de distribuciones
total_data.hist(figsize=(10, 8))
plt.suptitle("Distribuci√≥n de variables antes de limpieza")
plt.show()

###############   3. Data Preparation
interim_data = total_data.copy()

# Reemplazar ceros por NaN (ya hecho antes)
interim_data[cols_with_zeros] = interim_data[cols_with_zeros].replace(0, np.nan)

# Imputar valores faltantes con la mediana sin usar inplace en el slice
for col in cols_with_zeros:
    median_val = interim_data[col].median()
    interim_data[col] = interim_data[col].fillna(median_val)

# Verificar que ya no haya nulos
print("\nValores nulos despu√©s de la imputaci√≥n:")
print(interim_data.isnull().sum())

# Estad√≠sticas descriptivas despu√©s de la limpieza
print("\nEstad√≠sticas Descriptivas (dataset limpio):")
print(interim_data.describe())

#No se va a escalar o normalizar ya que se utilizar√° el modelo de arboles de decision 

# Identificaci√≥n de Outliers

# se utilizar√° IQR IQR significa Interquartile Range, o rango intercuart√≠lico. 
# Es una medida de dispersi√≥n que se centra en la parte ‚Äúcentral‚Äù de tus datos, ignorando valores extremos.

# Columnas num√©ricas a revisar
num_cols = ["Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age"]

# Funci√≥n para detectar outliers
def detect_outliers(df, cols):
    outlier_dict = {}
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = df[(df[col] < lower) | (df[col] > upper)][col]
        outlier_dict[col] = outliers
        print(f"{col}: {len(outliers)} outliers")
    return outlier_dict

outliers = detect_outliers(interim_data, num_cols)

#Capear (winsorize): reemplazar valores extremos por percentiles.
#Eliminar: solo si hay muy pocos outliers.
#qu√≠ usamos capping al 1er y 99¬∫ percentil, robusto para √°rboles:

for col in num_cols:
    lower = interim_data[col].quantile(0.01)
    upper = interim_data[col].quantile(0.99)
    interim_data[col] = np.clip(interim_data[col], lower, upper)

# ------------Importancia de las variables

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Separar variables
X = interim_data.drop("Outcome", axis=1)
y = interim_data["Outcome"]

# Separar la data en train y test

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar √°rbol de decisi√≥n
tree = DecisionTreeClassifier(random_state=42)
tree.fit(X_train, y_train)

# Predicci√≥n y evaluaci√≥n
y_pred = tree.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Feature importance
importances = pd.Series(tree.feature_importances_, index=X.columns).sort_values(ascending=False)
print("\nFeature Importance:")
print(importances)

# Visualizaci√≥n
importances.plot(kind="bar", figsize=(10,5), title="Feature Importance")
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.tree import export_text
import joblib  # Para guardar el modelo

############### 4. Probar distintos criterios de pureza #################

criterios = ['gini', 'entropy', 'log_loss']
for crit in criterios:
    tree = DecisionTreeClassifier(random_state=42, criterion=crit)
    tree.fit(X_train, y_train)
    y_pred = tree.predict(X_test)
    print(f"\nCriterio: {crit}")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))
    
    # Visualizar feature importance
    importances = pd.Series(tree.feature_importances_, index=X.columns).sort_values(ascending=False)
    print("Feature Importance:")
    print(importances)
    importances.plot(kind="bar", figsize=(10,5), title=f"Feature Importance ({crit})")
    plt.show()

############### 5. Optimizaci√≥n de hiperpar√°metros #################

# Definir el grid de b√∫squeda
param_grid = {
    'max_depth': [3, 5, 7, 9, None],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 2, 5, 10],
    'criterion': ['gini', 'entropy', 'log_loss']
}

grid_search = GridSearchCV(
    DecisionTreeClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("\nMejores hiperpar√°metros encontrados:")
print(grid_search.best_params_)

# Evaluar modelo optimizado
best_tree = grid_search.best_estimator_
y_pred_best = best_tree.predict(X_test)
print("\nEvaluaci√≥n del √°rbol optimizado:")
print("Accuracy:", accuracy_score(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))

# Guardar el modelo optimizado
joblib.dump(best_tree, "decision_tree_optimized.pkl")
print("\nModelo guardado como 'decision_tree_optimized.pkl'")

# visualizar √°rbol en texto
tree_rules = export_text(best_tree, feature_names=list(X.columns))
print("\nReglas del √°rbol optimizado:")
print(tree_rules)

#-------------------------------------------------------------------------- RANDOM FOREST
#random forest es una agrupaci√≥n de √°rboles generados con porciones aleatorias de los datos y con criterios tambi√©n aleatorios. 
# Esta visi√≥n nos permitir√≠a mejorar la efectividad del modelo cuando un √°rbol individual no es suficiente.
#En este proyecto se centrar√° en esta idea entrenando el conjunto de datos para mejorar el accuracy
#Random Forest suele superar a un solo √°rbol porque reduce la varianza al promediar muchos √°rboles.

############### 0. Importar librer√≠as necesarias ###############
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import joblib

############### 1. Entrenar Random Forest ###############

# Definir el modelo base
rf = RandomForestClassifier(
    n_estimators=100,        # n√∫mero de √°rboles, se puede aumentar a 200-500, m√°s √°rboles generalmente mejora el accuracy 
    #pero sube el tiempo de entrenamiento
    max_depth=None,           # profundidad m√°xima de los √°rboles, limitarlo puede evitar overfitting.
    min_samples_split=2,      # m√≠nimo de muestras para dividir un nodo
    min_samples_leaf=1,       # m√≠nimo de muestras por hoja
    criterion='gini',         # criterio de pureza
    random_state=42,
    n_jobs=-1                 # usar todos los cores
)

# Entrenar
rf.fit(X_train, y_train)

# Predicciones
y_pred_rf = rf.predict(X_test)

# Evaluaci√≥n
print("Accuracy Random Forest:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

############### 2. Importancia de las variables ###############
importances_rf = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
print("\nFeature Importance Random Forest:")
print(importances_rf)

# Visualizaci√≥n
importances_rf.plot(kind="bar", figsize=(10,5), title="Feature Importance (Random Forest)")
plt.show()

############### 3. Probar variando hiperpar√°metros ###############
from sklearn.model_selection import GridSearchCV

param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy']
}

grid_search_rf = GridSearchCV(
    RandomForestClassifier(random_state=42, n_jobs=-1),
    param_grid_rf,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search_rf.fit(X_train, y_train)

print("\nMejores hiperpar√°metros Random Forest:")
print(grid_search_rf.best_params_)

# Evaluar el mejor modelo
best_rf = grid_search_rf.best_estimator_
y_pred_best_rf = best_rf.predict(X_test)
print("\nEvaluaci√≥n del Random Forest optimizado:")
print("Accuracy:", accuracy_score(y_test, y_pred_best_rf))
print(classification_report(y_test, y_pred_best_rf))

############### 4. Guardar el modelo ###############
joblib.dump(best_rf, "random_forest_optimized.pkl")
print("\nModelo Random Forest guardado como 'random_forest_optimized.pkl'")

#-------------------------------------------------------------------------- COMPARACI√ìN DE MODELOS
from sklearn.metrics import precision_score, recall_score, f1_score

print("\n================= COMPARACI√ìN FINAL ENTRE MODELOS =================")

# --- M√©tricas √Årbol de Decisi√≥n Optimizado ---
acc_tree = accuracy_score(y_test, y_pred_best)
prec_tree = precision_score(y_test, y_pred_best)
rec_tree = recall_score(y_test, y_pred_best)
f1_tree = f1_score(y_test, y_pred_best)

# --- M√©tricas Random Forest Optimizado ---
acc_rf = accuracy_score(y_test, y_pred_best_rf)
prec_rf = precision_score(y_test, y_pred_best_rf)
rec_rf = recall_score(y_test, y_pred_best_rf)
f1_rf = f1_score(y_test, y_pred_best_rf)

# --- Mostrar comparativa num√©rica ---
print(f"\nAccuracy √Årbol de Decisi√≥n: {acc_tree:.4f}")
print(f"Accuracy Random Forest:     {acc_rf:.4f}")
print(f"Mejora en accuracy:         {((acc_rf - acc_tree) * 100):.2f}%")

print("\n--- M√©tricas detalladas ---")
print(f"{'M√©trica':<15}{'√Årbol de Decisi√≥n':<20}{'Random Forest'}")
print(f"{'Accuracy':<15}{acc_tree:<20.4f}{acc_rf:.4f}")
print(f"{'Precision':<15}{prec_tree:<20.4f}{prec_rf:.4f}")
print(f"{'Recall':<15}{rec_tree:<20.4f}{rec_rf:.4f}")
print(f"{'F1-Score':<15}{f1_tree:<20.4f}{f1_rf:.4f}")

# --- Visualizaci√≥n de comparaci√≥n ---
labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
tree_scores = [acc_tree, prec_tree, rec_tree, f1_tree]
rf_scores = [acc_rf, prec_rf, rec_rf, f1_rf]

x = np.arange(len(labels))
width = 0.35

fig, ax = plt.subplots(figsize=(8,5))
bars1 = ax.bar(x - width/2, tree_scores, width, label='Decision Tree', color='skyblue')
bars2 = ax.bar(x + width/2, rf_scores, width, label='Random Forest', color='orange')

ax.set_ylabel('Puntaje')
ax.set_title('Comparaci√≥n de m√©tricas entre √Årbol de Decisi√≥n y Random Forest')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

for bar in bars1 + bars2:
    yval = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f'{yval:.2f}', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

# --- Conclusi√≥n r√°pida ---
if acc_rf > acc_tree:
    print(f"\n‚úÖ El modelo Random Forest supera al √Årbol de Decisi√≥n en un {((acc_rf - acc_tree)*100):.2f}% de accuracy promedio.")
else:
    print(f"\n‚ö†Ô∏è El √Årbol de Decisi√≥n tuvo mejor desempe√±o que el Random Forest en este caso.")


#-----------------------------BOOSTING 
#Boosting es una composici√≥n de modelos (generalmente √°rboles de decisi√≥n) secuencial en la cual el modelo nuevo 
# persigue corregir los errores del anterior.

#√Årbol de decisi√≥n ‚Üí aprende de una sola estructura (alta varianza).
#Random Forest ‚Üí promedia √°rboles entrenados en paralelo (reduce varianza).
#Boosting ‚Üí entrena √°rboles de forma secuencial, donde cada nuevo √°rbol corrige los errores del anterior 
# (reduce sesgo y mejora precisi√≥n). Esto hace que Boosting (sobre todo Gradient Boosting, XGBoost, AdaBoost o LightGBM) 
# logre mejores resultados en datasets tabulares.

#XGBoost (eXtreme Gradient Boosting) es la implementaci√≥n m√°s eficiente del algoritmo de gradient boosting. 
# Se ha desarrollado buscando rapidez y precisi√≥n, y hasta ahora es la mejor implementaci√≥n, 
# superando en tiempos de entrenamiento a la de sklearn. 
# La reducci√≥n de tiempos se debe a que proporciona m√©todos para paralelizar las tareas, 
# as√≠ como flexibilidad a la hora de entrenar el modelo y es m√°s robusto, 
# pudiendo incluir mecanismos de poda de los √°rboles para ahorrar tiempos de procesamiento. 
# Siempre que la tengamos disponible, esta es la alternativa que se deber√≠a utilizar frente a la de sklearn.


from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Modelo base
xgb = XGBClassifier(
    n_estimators=200,       # Cuantos m√°s √°rboles, menor sesgo pero mayor riesgo de sobreajuste y tiempo de c√≥mputo
                            #n√∫mero de √°rboles 100 √°rboles suelen ser suficientes para datasets simples.
                            #500‚Äì1000 se usan en datasets grandes o muy no lineales.
                            #200 es un punto intermedio ideal para obtener buena performance sin sobreentrenar ni tardar mucho

    learning_rate=0.05,     # Controla cu√°nto peso se da a cada nuevo √°rbol en la correcci√≥n de errores.
                            #velocidad de aprendizaje (m√°s bajo = m√°s preciso pero m√°s lento)
                            #Valores altos (‚â•0.1) ‚Üí el modelo aprende r√°pido, pero puede sobreajustar.
                            #Valores bajos (‚â§0.03) ‚Üí el modelo aprende m√°s lento pero m√°s fino.
                            #0.05 es un punto seguro que permite combinar estabilidad y precisi√≥n.
                            #En boosting, hay una regla emp√≠rica: ‚ÄúA menor learning_rate, mayor n√∫mero de √°rboles necesitas‚Äù.

    max_depth=4,            # Profundidad de los √°rboles Determina la profundidad m√°xima de cada √°rbol base.
                            # √Årboles m√°s profundos ‚Üí mayor capacidad de capturar interacciones, pero tambi√©n m√°s overfitting.
                            # En este dataset, las relaciones entre variables (como Glucose, BMI, Age, etc.) 
                            # no son extremadamente complejas. Profundidades entre 3 y 6 suelen ser √≥ptimas.
                            #Con max_depth=4, el modelo mantiene buena generalizaci√≥n y baja varianza.

    subsample=0.8,          # fracci√≥n de observaciones usadas en cada iteraci√≥n
                            #Significa que cada √°rbol usa solo el 80 % de las filas de entrenamiento, seleccionadas aleatoriamente.
                            #Este ‚Äúbagging parcial‚Äù introduce diversidad entre √°rboles y reduce la varianza.
                            #Si se pone en 1.0, usa todos los datos en cada iteraci√≥n ‚Üí m√°s riesgo de sobreajuste.
                            #0.8 es un valor cl√°sico que mejora la robustez sin perder demasiada informaci√≥n.
    colsample_bytree=0.8,   # fracci√≥n de columnas usadas en cada iteraci√≥n
                            #Indica que cada √°rbol usa solo el 80 % de las columnas.
                            #Tambi√©n sirve para diversificar los √°rboles y evitar que todos dependan de las mismas variables 
                            # (por ejemplo, ‚ÄúGlucose‚Äù). Es equivalente a lo que hace Random Forest al usar subconjuntos de features.
                            #En datasets con menos de 10 variables (como este), 0.8 ayuda a evitar correlaciones 
                            # fuertes entre √°rboles.
    random_state=42,
    eval_metric='logloss'  #Define la m√©trica interna de evaluaci√≥n durante el entrenamiento.
                            #En clasificaci√≥n binaria, 'logloss' (logarithmic loss) es m√°s sensible al desbalanceo de clases 
                            #que accuracy y penaliza m√°s los errores de alta confianza.
                            #Es el est√°ndar para calibrar la probabilidad de predicci√≥n (no solo la clase).
)

# Entrenar modelo
xgb.fit(X_train, y_train)

# Predicciones
y_pred_xgb = xgb.predict(X_test)

# Evaluaci√≥n
print("Accuracy de XGBoost:", accuracy_score(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))


#----------------------------------- OPTIMIZACION HIPER PARAMETROS

from sklearn.model_selection import GridSearchCV

param_grid_xgb = {
    'n_estimators': [100, 200, 300],   #Menos de 100 suele ser insuficiente para capturar relaciones complejas.
    'max_depth': [3, 4, 5, 6],         #√Årboles muy profundos (>6) tienden a sobreajustar. √Årboles muy superficiales (<3) pierden capacidad predictiva.
    'learning_rate': [0.01, 0.05, 0.1], #0.1 es el valor por defecto en XGBoost (aprendizaje r√°pido). 0.05 y 0.01 permiten un aprendizaje m√°s lento pero m√°s preciso y estable
    'subsample': [0.7, 0.8, 1.0],     #0.8 es un est√°ndar muy usado.
    'colsample_bytree': [0.7, 0.8, 1.0]
}

grid_xgb = GridSearchCV(
    XGBClassifier(random_state=42, eval_metric='logloss'),
    param_grid_xgb,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_xgb.fit(X_train, y_train)

print("\nMejores hiperpar√°metros XGBoost:")
print(grid_xgb.best_params_)

best_xgb = grid_xgb.best_estimator_
y_pred_best_xgb = best_xgb.predict(X_test)

print("\nEvaluaci√≥n del modelo XGBoost optimizado:")
print("Accuracy:", accuracy_score(y_test, y_pred_best_xgb))
print(classification_report(y_test, y_pred_best_xgb))

#--------------------------------IMPORTANCIA DE LAS VARIABLES------------

importances_xgb = pd.Series(best_xgb.feature_importances_, index=X.columns).sort_values(ascending=False)
print("\nImportancia de las VAriables XGBoost:")
print(importances_xgb)

importances_xgb.plot(kind="bar", figsize=(10,5), title="Importancia Variables (XGBoost)")
plt.show()

#------------------------------GUARAR MODELO

joblib.dump(best_xgb, "xgboost_optimized.pkl")
print("\nModelo XGBoost guardado como 'xgboost_optimized.pkl'")


# --------------------------------------------- COMPARAR MODELOS

# --- M√©tricas XGBoost ---
acc_xgb = accuracy_score(y_test, y_pred_best_xgb)
prec_xgb = precision_score(y_test, y_pred_best_xgb)
rec_xgb = recall_score(y_test, y_pred_best_xgb)
f1_xgb = f1_score(y_test, y_pred_best_xgb)

# --- Comparativa ---
print("\n================= COMPARACI√ìN FINAL ENTRE MODELOS =================")
print(f"{'M√©trica':<15}{'Decision Tree':<20}{'Random Forest':<20}{'XGBoost'}")
print(f"{'Accuracy':<15}{acc_tree:<20.4f}{acc_rf:<20.4f}{acc_xgb:.4f}")
print(f"{'Precision':<15}{prec_tree:<20.4f}{prec_rf:<20.4f}{prec_xgb:.4f}")
print(f"{'Recall':<15}{rec_tree:<20.4f}{rec_rf:<20.4f}{rec_xgb:.4f}")
print(f"{'F1-Score':<15}{f1_tree:<20.4f}{f1_rf:<20.4f}{f1_xgb:.4f}")

# --- Visualizaci√≥n ---
labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
tree_scores = [acc_tree, prec_tree, rec_tree, f1_tree]
rf_scores = [acc_rf, prec_rf, rec_rf, f1_rf]
xgb_scores = [acc_xgb, prec_xgb, rec_xgb, f1_xgb]

x = np.arange(len(labels))
width = 0.25

fig, ax = plt.subplots(figsize=(9,5))
ax.bar(x - width, tree_scores, width, label='Decision Tree')
ax.bar(x, rf_scores, width, label='Random Forest')
ax.bar(x + width, xgb_scores, width, label='XGBoost')

ax.set_ylabel('Score')
ax.set_title('Comparaci√≥n de modelos de clasificaci√≥n (Diabetes)')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()
plt.show()


#### OPTIMIZACION DE PARAMETROS Y CORRECCIONES 

""" scale_pos_weight ‚Üí corrige desbalance de clases.
    early_stopping_rounds=20 ‚Üí evita sobreajuste de √°rboles profundos.
    StratifiedKFold ‚Üí mantiene proporci√≥n de clases en CV.
    scoring='f1' ‚Üí prioriza balance entre recall y precision, ideal en medicina.
    Grid m√°s amplio ‚Üí explora mejor combinaciones de learning_rate, n_estimators, subsample y colsample_bytree."""

from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# ------------------------ Ajustar scale_pos_weight ------------------------
# Calcula el peso de la clase minoritaria
scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])
print(f"scale_pos_weight: {scale_pos_weight:.2f}")

# ------------------------ Modelo base ------------------------
xgb_base = XGBClassifier(
    random_state=42,
    eval_metric='logloss'
  )

# ------------------------ Grid de hiperpar√°metros ------------------------
param_grid_xgb = {
    'n_estimators': [200, 300, 500],
    'max_depth': [3, 4, 5, 6],
    'learning_rate': [0.01, 0.03, 0.05, 0.1],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9],
}

# ------------------------ Estrategia de validaci√≥n cruzada ------------------------
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)


grid_xgb = GridSearchCV(
    estimator=XGBClassifier(random_state=42),
    param_grid=param_grid_xgb,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    error_score='raise'
)

# ------------------------ Entrenamiento ------------------------
grid_xgb.fit(X_train, y_train)
print("\nMejores hiperpar√°metros XGBoost:")
print(grid_xgb.best_params_)



# ------------------------ Mejor modelo ------------------------
best_xgb = grid_xgb.best_estimator_
y_pred_best_xgb = best_xgb.predict(X_test)

# ------------------------ Evaluaci√≥n ------------------------
acc_xgb = accuracy_score(y_test, y_pred_best_xgb)
prec_xgb = precision_score(y_test, y_pred_best_xgb)
rec_xgb = recall_score(y_test, y_pred_best_xgb)
f1_xgb = f1_score(y_test, y_pred_best_xgb)

print("\n===== Evaluaci√≥n XGBoost Optimizado =====")
print(f"Accuracy:  {acc_xgb:.4f}")
print(f"Precision: {prec_xgb:.4f}")
print(f"Recall:    {rec_xgb:.4f}")
print(f"F1-Score:  {f1_xgb:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_best_xgb))

# ------------------------ Importancia de variables ------------------------
import pandas as pd
import matplotlib.pyplot as plt

importances_xgb = pd.Series(best_xgb.feature_importances_, index=X.columns).sort_values(ascending=False)
print("\nImportancia de Variables (XGBoost Optimizado):")
print(importances_xgb)

importances_xgb.plot(kind="bar", figsize=(10,5), title="Importancia Variables (XGBoost Optimizado)")
plt.show()

# ------------------------ Guardar modelo ------------------------
import joblib
joblib.dump(best_xgb, "xgboost_optimized_v2.pkl")
print("\nModelo XGBoost optimizado guardado como 'xgboost_optimized_v2.pkl'")

#---------------------------------- COMPARACION FINAL--------------------

# ------------------------ M√©tricas ------------------------
models = {
    "Decision Tree": y_pred_best,
    "Random Forest": y_pred_best_rf,
    "XGBoost Base": y_pred_xgb,
    "XGBoost Optimizado": y_pred_best_xgb
}

metrics = {}
for name, y_pred in models.items():
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    metrics[name] = [acc, prec, rec, f1]

# ------------------------ Mostrar tabla ------------------------
labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
print(f"{'M√©trica':<15}{'Decision Tree':<18}{'Random Forest':<18}{'XGBoost Base':<18}{'XGBoost Optimizado'}")
for i, label in enumerate(labels):
    print(f"{label:<15}{metrics['Decision Tree'][i]:<18.4f}"
          f"{metrics['Random Forest'][i]:<18.4f}"
          f"{metrics['XGBoost Base'][i]:<18.4f}"
          f"{metrics['XGBoost Optimizado'][i]:.4f}")

# ------------------------ Visualizaci√≥n ------------------------
x = np.arange(len(labels))
width = 0.2

fig, ax = plt.subplots(figsize=(10,5))
ax.bar(x - 1.5*width, metrics['Decision Tree'], width, label='Decision Tree', color='skyblue')
ax.bar(x - 0.5*width, metrics['Random Forest'], width, label='Random Forest', color='orange')
ax.bar(x + 0.5*width, metrics['XGBoost Base'], width, label='XGBoost Base', color='green')
ax.bar(x + 1.5*width, metrics['XGBoost Optimizado'], width, label='XGBoost Optimizado', color='red')

ax.set_ylabel('Score')
ax.set_title('Comparaci√≥n de Modelos de Clasificaci√≥n (Diabetes)')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

# A√±adir valores encima de cada barra
for i in range(len(labels)):
    for j, key in enumerate(models.keys()):
        yval = metrics[key][i]
        ax.text(x[i] + (j-1.5)*width, yval + 0.01, f'{yval:.2f}', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

#---- METRICAS MAS IMPORTANTES PARA OPTIMIZAR
#M√©trica	Prioridad	Raz√≥n
#Recall	‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê	Evitar falsos negativos. No queremos decirle a alguien ‚Äúest√°s bien‚Äù cuando est√° enfermo.
#F1-Score	‚≠ê‚≠ê‚≠ê‚≠ê	Balancea recall y precisi√≥n. Ideal cuando hay clases desbalanceadas (como diabetes).
#Es mejor detectar a alguien enfermo aunque sea una falsa alarma, que dejar pasar un caso real.

# OPTIMIZANDO RECALL Y F1

# Calcular peso de clases para favorecer Recall (clase positiva)
pos = np.sum(y_train == 1)
neg = np.sum(y_train == 0)
scale_pos_weight = neg / pos

xgb_recall = XGBClassifier(
    random_state=42,
    objective='binary:logistic',
    eval_metric='logloss',
    scale_pos_weight=scale_pos_weight
)

param_dist_recall = {
    'n_estimators': [200, 300, 400],
    'learning_rate': [0.01, 0.03, 0.05],
    'max_depth': [2, 3, 4],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2],
    'reg_alpha': [0, 0.01, 0.1],
    'reg_lambda': [1, 1.5, 2]
}

from sklearn.model_selection import RandomizedSearchCV

random_search_recall = RandomizedSearchCV(
    estimator=xgb_recall,
    param_distributions=param_dist_recall,
    n_iter=25,                     # m√°s bajo = m√°s r√°pido, puedes subir a 50 si quieres m√°ximo performance
    scoring='f1',                  # optimizamos F1
    cv=5,
    verbose=1,
    n_jobs=-1
)

random_search_recall.fit(
    X_train, y_train
)

best_xgb_recall = random_search_recall.best_estimator_

y_pred_recall = best_xgb_recall.predict(X_test)

print("\n===== XGBoost Optimizado para Recall & F1 =====")
print("Best Params:", random_search_recall.best_params_)
print("Accuracy:", accuracy_score(y_test, y_pred_recall))
print("Recall:", recall_score(y_test, y_pred_recall))
print("F1 Score:", f1_score(y_test, y_pred_recall))
print("\nClassification Report:\n", classification_report(y_test, y_pred_recall))

# --- M√©tricas XGBoost ---
acc_xgb = accuracy_score(y_test, y_pred_xgb)
prec_xgb = precision_score(y_test, y_pred_xgb)
rec_xgb = recall_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb)

print("\n================= COMPARACI√ìN FINAL ENTRE MODELOS =================")
print(f"{'M√©trica':<15}{'Decision Tree':<18}{'Random Forest':<18}{'XGBoost'}")
print(f"{'Accuracy':<15}{acc_tree:<18.4f}{acc_rf:<18.4f}{acc_xgb:.4f}")
print(f"{'Precision':<15}{prec_tree:<18.4f}{prec_rf:<18.4f}{prec_xgb:.4f}")
print(f"{'Recall':<15}{rec_tree:<18.4f}{rec_rf:<18.4f}{rec_xgb:.4f}")
print(f"{'F1-Score':<15}{f1_tree:<18.4f}{f1_rf:<18.4f}{f1_xgb:.4f}")

# --- Visualizaci√≥n de comparaci√≥n ---
labels = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
tree_scores = [acc_tree, prec_tree, rec_tree, f1_tree]
rf_scores = [acc_rf, prec_rf, rec_rf, f1_rf]
xgb_scores = [acc_xgb, prec_xgb, rec_xgb, f1_xgb]

x = np.arange(len(labels))
width = 0.25

fig, ax = plt.subplots(figsize=(9,5))
bars1 = ax.bar(x - width, tree_scores, width, label='Decision Tree')
bars2 = ax.bar(x, rf_scores, width, label='Random Forest')
bars3 = ax.bar(x + width, xgb_scores, width, label='XGBoost')

ax.set_ylabel('Puntaje')
ax.set_title('Comparaci√≥n de m√©tricas entre modelos')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

for bars in [bars1, bars2, bars3]:
    for bar in bars:
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{bar.get_height():.2f}', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

#----------------------------------- OPTIMIZACION HIPER PARAMETROS

from sklearn.model_selection import GridSearchCV

param_grid_xgb = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [3, 4, 5],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}

grid_search_xgb = GridSearchCV(
    XGBClassifier(
        random_state=42,
        eval_metric='logloss',
        use_label_encoder=False
    ),
    param_grid_xgb,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search_xgb.fit(X_train, y_train)

print("\nMejores hiperpar√°metros XGBoost:")
print(grid_search_xgb.best_params_)

# Evaluar mejor modelo
best_xgb = grid_search_xgb.best_estimator_
y_pred_best_xgb = best_xgb.predict(X_test)

print("\nEvaluaci√≥n del XGBoost optimizado:")
print("Accuracy:", accuracy_score(y_test, y_pred_best_xgb))
print(classification_report(y_test, y_pred_best_xgb))

# Guardar modelo
joblib.dump(best_xgb, "xgboost_optimized.pkl")
print("\nModelo XGBoost guardado como 'xgboost_optimized.pkl'")

#----------------------------------- OPTIMIZACION HIPERPAR√ÅMETROS XGBOOST

from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
import joblib

param_grid_xgb = {
    'n_estimators': [100, 200, 300],     # n√∫mero de √°rboles
    'learning_rate': [0.01, 0.05, 0.1],  # velocidad de aprendizaje
    'max_depth': [3, 4, 5],              # profundidad del √°rbol
    'subsample': [0.7, 0.8, 1.0],        # fracci√≥n de filas
    'colsample_bytree': [0.7, 0.8, 1.0]  # fracci√≥n de columnas
}

xgb_model = XGBClassifier(
    random_state=42,
    eval_metric='logloss'
)

grid_search_xgb = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid_xgb,
    cv=3,                 # 5 es m√°s preciso pero m√°s lento
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search_xgb.fit(X_train, y_train)

print("\nMejores hiperpar√°metros de XGBoost:")
print(grid_search_xgb.best_params_)

best_xgb = grid_search_xgb.best_estimator_
y_pred_best_xgb = best_xgb.predict(X_test)

print("\nEvaluaci√≥n XGBoost Optimizado:")
print("Accuracy:", accuracy_score(y_test, y_pred_best_xgb))
print(classification_report(y_test, y_pred_best_xgb))

# Guardar modelo
joblib.dump(best_xgb, "xgboost_optimized.pkl")
print("\nModelo XGBoost guardado como 'xgboost_optimized.pkl'")

#------------------------- COMPARACI√ìN FINAL ENTRE LOS 3 MODELOS

models = {
    "Decision Tree": (y_pred_best),
    "Random Forest": (y_pred_best_rf),
    "XGBoost": (y_pred_best_xgb)
}

print("\n=========== COMPARACI√ìN FINAL MODELOS ===========")
for name, y_pred in models.items():
    print(f"\nüìå Modelo: {name}")
    print(f"Accuracy:  {accuracy_score(y_test, y_pred):.4f}")
    print(f"Precision: {precision_score(y_test, y_pred):.4f}")
    print(f"Recall:    {recall_score(y_test, y_pred):.4f}")
    print(f"F1 Score:  {f1_score(y_test, y_pred):.4f}")